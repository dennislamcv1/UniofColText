{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hhG5k8eHapxL"},"source":["# Imports and Loading in the DTM\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5taJZayvAU4W","executionInfo":{"status":"ok","timestamp":1699574661970,"user_tz":420,"elapsed":958,"user":{"displayName":"Chris Vargo (chrisjvargo)","userId":"16950548609048188423"}},"outputId":"30d99ecc-c827-48a4-94b7-fd38475e158f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"VwPzhqm201BF","executionInfo":{"status":"ok","timestamp":1699574661970,"user_tz":420,"elapsed":7,"user":{"displayName":"Chris Vargo (chrisjvargo)","userId":"16950548609048188423"}}},"source":["import os\n","\n","try:\n","  import tmtoolkit\n","except:\n","  !pip install -U \"tmtoolkit[recommended]\"\n","  import tmtoolkit"],"execution_count":12,"outputs":[]},{"cell_type":"code","source":["try:\n","  from tmtoolkit.topicmod.tm_lda import compute_models_parallel\n","except:\n","  !pip install tmtoolkit['lda']\n","  from tmtoolkit.topicmod.tm_lda import compute_models_parallel"],"metadata":{"id":"bHLu2ZwiEQAl","executionInfo":{"status":"ok","timestamp":1699574661970,"user_tz":420,"elapsed":5,"user":{"displayName":"Chris Vargo (chrisjvargo)","userId":"16950548609048188423"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import pickle\n","import scipy.sparse\n","import logging\n","import warnings"],"metadata":{"id":"t6vWB5ojEWa-","executionInfo":{"status":"ok","timestamp":1699574661970,"user_tz":420,"elapsed":5,"user":{"displayName":"Chris Vargo (chrisjvargo)","userId":"16950548609048188423"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["try:\n","  from lda import LDA\n","except:\n","  !pip install lda"],"metadata":{"id":"p7B4XSGYET43","executionInfo":{"status":"ok","timestamp":1699574661971,"user_tz":420,"elapsed":5,"user":{"displayName":"Chris Vargo (chrisjvargo)","userId":"16950548609048188423"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6RZN3fjq6zM","executionInfo":{"status":"ok","timestamp":1699574663591,"user_tz":420,"elapsed":1624,"user":{"displayName":"Chris Vargo (chrisjvargo)","userId":"16950548609048188423"}}},"source":["working_directory = '/content/drive/MyDrive/2work/MSDS_marketing_text_analytics/master_files/2_topic_modeling'\n","\n","doc_labels_sm = pickle.load(open('%s/doc_labels_sm.p' % working_directory, 'rb'))\n","doc_labels_bg = pickle.load(open('%s/doc_labels_bg.p' % working_directory, 'rb'))\n","\n","\n","dtm_sm = scipy.sparse.load_npz('%s/small_dtm.npz' % working_directory)\n","dtm_bg = scipy.sparse.load_npz('%s/big_dtm.npz' % working_directory)\n","\n","vocab_bg = pickle.load(open('%s/big_vocab.p' % working_directory, 'rb'))\n","vocab_sm = pickle.load(open('%s/small_vocab.p' % working_directory, 'rb'))"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5yXISGPklTa9"},"source":["# Creating Models"]},{"cell_type":"code","metadata":{"id":"MVmtHtVGzryr","executionInfo":{"status":"ok","timestamp":1699574663591,"user_tz":420,"elapsed":5,"user":{"displayName":"Chris Vargo (chrisjvargo)","userId":"16950548609048188423"}}},"source":["# suppress the \"INFO\" messages and warnings from lda\n","logger = logging.getLogger('lda')\n","logger.addHandler(logging.NullHandler())\n","logger.propagate = False\n","warnings.filterwarnings('ignore')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"WU1HgxcHGXek","executionInfo":{"status":"ok","timestamp":1699574708783,"user_tz":420,"elapsed":45195,"user":{"displayName":"Chris Vargo (chrisjvargo)","userId":"16950548609048188423"}}},"source":["# set data to use\n","dtms = {\n","    'bigger': dtm_bg,\n","    'smaller': dtm_sm\n","}\n","\n","# and fixed hyperparameters\n","# Here, alpha represents document-topic density - with a higher alpha, documents\n","# are made up of more topics, and with lower alpha, documents contain fewer topics.\n","#Beta represents topic-word density - with a high beta, topics are made up of\n","#most of the words in the corpus, and with a low beta they consist of few words.\n","# https://www.thoughtvector.io/blog/lda-alpha-and-beta-parameters-the-intuition/\n","lda_params = {\n","    'n_topics': 16,\n","    'eta': .01,\n","    'n_iter': 500,\n","    'random_state': 20191122,  # to make results reproducible\n","    'alpha': 1/16\n","}\n","\n","models = compute_models_parallel(dtms, constant_parameters=lda_params)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRCxJErMpY0I","executionInfo":{"status":"ok","timestamp":1699574708784,"user_tz":420,"elapsed":15,"user":{"displayName":"Chris Vargo (chrisjvargo)","userId":"16950548609048188423"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aec715c0-bb1c-4928-aa6c-854daca8080f"},"source":["from tmtoolkit.topicmod.model_io import print_ldamodel_topic_words\n","\n","model_sm = models['smaller'][0][1]\n","print_ldamodel_topic_words(model_sm.topic_word_, vocab_sm, top_n=5)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["topic_1\n","> #1. size (0.157635)\n","> #2. shoe (0.112448)\n","> #3. small (0.093707)\n","> #4. run (0.070593)\n","> #5. order (0.062367)\n","topic_2\n","> #1. great (0.183331)\n","> #2. shoe (0.116051)\n","> #3. fit (0.100661)\n","> #4. look (0.065929)\n","> #5. price (0.056258)\n","topic_3\n","> #1. shoe (0.128435)\n","> #2. foot (0.110740)\n","> #3. wear (0.103459)\n","> #4. day (0.067901)\n","> #5. comfortable (0.059773)\n","topic_4\n","> #1. sneaker (0.149575)\n","> #2. pair (0.063499)\n","> #3. love (0.060476)\n","> #4. wear (0.052311)\n","> #5. comfortable (0.049590)\n","topic_5\n","> #1. shoe (0.161562)\n","> #2. great (0.076362)\n","> #3. comfortable (0.074376)\n","> #4. love (0.062957)\n","> #5. run (0.057992)\n","topic_6\n","> #1. shoe (0.140876)\n","> #2. pair (0.105473)\n","> #3. nike (0.077798)\n","> #4. wear (0.073456)\n","> #5. buy (0.071763)\n","topic_7\n","> #1. size (0.175838)\n","> #2. 10 (0.158691)\n","> #3. shoe (0.071061)\n","> #4. 1 (0.069248)\n","> #5. wear (0.055068)\n","topic_8\n","> #1. shoe (0.186363)\n","> #2. run (0.124834)\n","> #3. 1 (0.066856)\n","> #4. nike (0.059276)\n","> #5. foot (0.037014)\n","topic_9\n","> #1. shoe (0.146513)\n","> #2. love (0.131275)\n","> #3. color (0.103579)\n","> #4. buy (0.068160)\n","> #5. comfortable (0.061262)\n","topic_10\n","> #1. shoe (0.238134)\n","> #2. foot (0.086095)\n","> #3. like (0.050991)\n","> #4. feel (0.044869)\n","> #5. good (0.044481)\n","topic_11\n","> #1. good (0.148358)\n","> #2. product (0.118997)\n","> #3. quality (0.084871)\n","> #4. nike (0.066922)\n","> #5. price (0.061493)\n","topic_12\n","> #1. like (0.101721)\n","> #2. look (0.084463)\n","> #3. fit (0.065719)\n","> #4. good (0.062290)\n","> #5. little (0.049032)\n","topic_13\n","> #1. watch (0.235098)\n","> #2. time (0.057311)\n","> #3. work (0.043164)\n","> #4. nike (0.041722)\n","> #5. like (0.041271)\n","topic_14\n","> #1. shoe (0.141439)\n","> #2. like (0.102495)\n","> #3. look (0.082830)\n","> #4. feel (0.081764)\n","> #5. great (0.072367)\n","topic_15\n","> #1. shoe (0.116506)\n","> #2. love (0.107601)\n","> #3. son (0.101916)\n","> #4. happy (0.054606)\n","> #5. fit (0.053962)\n","topic_16\n","> #1. 1 (0.157212)\n","> #2. size (0.101220)\n","> #3. order (0.094900)\n","> #4. shoe (0.084729)\n","> #5. fit (0.049672)\n"]}]},{"cell_type":"code","metadata":{"id":"s2Hf5RXtHdAu","executionInfo":{"status":"ok","timestamp":1699574708992,"user_tz":420,"elapsed":215,"user":{"displayName":"Chris Vargo (chrisjvargo)","userId":"16950548609048188423"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf07e60e-a0d2-48dd-8320-6518b3b2bb4f"},"source":["model_bg = models['bigger'][0][1]\n","print_ldamodel_topic_words(model_bg.topic_word_, vocab_bg, top_n=5)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["topic_1\n","> #1. size (0.103218)\n","> #2. 10 (0.063432)\n","> #3. shoe (0.061245)\n","> #4. fit (0.047294)\n","> #5. foot (0.040554)\n","topic_2\n","> #1. good (0.087190)\n","> #2. quality (0.060357)\n","> #3. product (0.059997)\n","> #4. fit (0.052947)\n","> #5. great (0.043811)\n","topic_3\n","> #1. love (0.108968)\n","> #2. color (0.067123)\n","> #3. shoe (0.063103)\n","> #4. comfortable (0.052687)\n","> #5. fit (0.048119)\n","topic_4\n","> #1. 1 (0.070153)\n","> #2. shoe (0.068224)\n","> #3. pair (0.063794)\n","> #4. wear (0.063325)\n","> #5. year (0.040445)\n","topic_5\n","> #1. size (0.145974)\n","> #2. 1 (0.085930)\n","> #3. shoe (0.052945)\n","> #4. small (0.049646)\n","> #5. order (0.047745)\n","topic_6\n","> #1. shoe (0.056506)\n","> #2. order (0.045869)\n","> #3. 1 (0.028653)\n","> #4. return (0.026993)\n","> #5. 10 (0.025333)\n","topic_7\n","> #1. sock (0.077557)\n","> #2. wear (0.047642)\n","> #3. foot (0.047409)\n","> #4. comfortable (0.034930)\n","> #5. boot (0.031781)\n","topic_8\n","> #1. great (0.064558)\n","> #2. shoe (0.055013)\n","> #3. love (0.054243)\n","> #4. fit (0.042209)\n","> #5. son (0.031301)\n","topic_9\n","> #1. shoe (0.138990)\n","> #2. great (0.071159)\n","> #3. good (0.056296)\n","> #4. comfortable (0.041491)\n","> #5. look (0.039712)\n","topic_10\n","> #1. watch (0.132257)\n","> #2. time (0.032140)\n","> #3. like (0.025397)\n","> #4. band (0.022711)\n","> #5. work (0.020886)\n","topic_11\n","> #1. shoe (0.077310)\n","> #2. color (0.069832)\n","> #3. look (0.055004)\n","> #4. like (0.049301)\n","> #5. black (0.042267)\n","topic_12\n","> #1. shoe (0.106685)\n","> #2. nike (0.074221)\n","> #3. pair (0.043820)\n","> #4. air (0.042375)\n","> #5. run (0.041085)\n","topic_13\n","> #1. shoe (0.117810)\n","> #2. foot (0.059306)\n","> #3. run (0.041152)\n","> #4. 1 (0.028155)\n","> #5. feel (0.024531)\n","topic_14\n","> #1. shoe (0.086935)\n","> #2. buy (0.046834)\n","> #3. pair (0.034381)\n","> #4. nike (0.029435)\n","> #5. price (0.028005)\n","topic_15\n","> #1. shoe (0.111691)\n","> #2. comfortable (0.066021)\n","> #3. great (0.049004)\n","> #4. wear (0.044443)\n","> #5. work (0.040116)\n","topic_16\n","> #1. son (0.057593)\n","> #2. love (0.056433)\n","> #3. bag (0.052568)\n","> #4. old (0.035252)\n","> #5. year (0.032005)\n"]}]},{"cell_type":"markdown","source":["When comparing two topic models with different document-term matrices (DTMs)—one with 2,500 words and another with 500 words—consider several factors to critically evaluate which topic model is better. Here are some top considerations for inspecting the top words for each topic across the two models:\n","\n","1. **Coherence and Interpretability**:\n","   - Check if the top words in each topic form a coherent theme that is easy to interpret. A good topic model should produce topics with words that are semantically related.\n","   - A larger DTM may include more specific or less frequent words that could potentially lead to more nuanced topics, while a smaller DTM may result in broader topics.\n","\n","2. **Distinctiveness of Topics**:\n","   - Evaluate whether the topics are distinct from each other or if there is significant overlap in top words across topics.\n","   - A model with a larger DTM might have more unique words that can help differentiate topics, but it could also introduce noise. Conversely, a smaller DTM might lead to more general topics that could overlap.\n","\n","3. **Relevance of Top Words**:\n","   - Consider the relevance of the top words to the topics. Are the top words representative of the topic, or are they too general or too obscure?\n","   - A larger DTM might include more relevant terms for each topic, but it could also contain irrelevant words that do not contribute to the topic's meaning."],"metadata":{"id":"tAKVfij7jcrZ"}}]}